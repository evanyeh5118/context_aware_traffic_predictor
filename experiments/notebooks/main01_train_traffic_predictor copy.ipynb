{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "from libs.TrafficGenerator import DatasetConvertor \n",
    "from libs.TrafficPredictor.ContextAssisted import PreparingDataset as PreparingDatasetCA\n",
    "from libs.TrafficPredictor.ContextAssisted import trainModelByDefaultSetting as trainModelCA\n",
    "from libs.TrafficPredictor.ContextAssisted import evaluateModel as evaluateModelCA\n",
    "from libs.TrafficPredictor.ContextAssisted import createModel as createModelCA\n",
    "#from libs.TrafficPredictor.ContextFree import PreparingDataset as PreparingDatasetCF\n",
    "#from libs.TrafficPredictor.ContextFree import trainModelByDefaultSetting as trainModelCF\n",
    "#from libs.TrafficPredictor.ContextFree import evaluateModel as evaluateModelCF\n",
    "#from libs.TrafficPredictor.ContextFree import createModel as createModelCF\n",
    "from libs import encode_float_filename, decode_float_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5_00e-01.txt\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "stringFile = encode_float_filename(0.5)\n",
    "floatFile = decode_float_filename(stringFile)\n",
    "print(stringFile)\n",
    "print(floatFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== thumb ============\n",
      "Forward: Compression rate:0.22314470485360394\n",
      "========== index ============\n",
      "Forward: Compression rate:0.24555334544091786\n",
      "========== middle ============\n",
      "Forward: Compression rate:0.24907031047306064\n"
     ]
    }
   ],
   "source": [
    "dbParams = 0.01\n",
    "direction = \"forward\"\n",
    "#dbParams = 0.15\n",
    "#direction = \"backward\"\n",
    "mode = \"fixed\"\n",
    "#mode = \"adaptive\"\n",
    "alpha = 0.5\n",
    "lenWindow_list = [10]\n",
    "train_ratio = 0.8\n",
    "\n",
    "rawDatasetFolder = \"Dataset\"\n",
    "datasetConverter = DatasetConvertor(rawDatasetFolder)\n",
    "datasetConverter.processDataset(dbParameter=dbParams, alpha=alpha, mode=mode, direction=direction)\n",
    "thumbUnit = datasetConverter.getDataUnit('thumb_fr')\n",
    "#thumbUnit = datasetConverter.getDataUnit('thumb_bk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== lenWindow = 10 =================\n",
      "Train size: 83253, Test size: 20814\n",
      "Size of train loader: 21, Size of test loader: 6\n",
      "Used device: cuda\n",
      "Size of model: 46969\n",
      "Seq2Seq(\n",
      "  (encoder): Encoder(\n",
      "    (lstm_layers): ModuleList(\n",
      "      (0): LSTM(1, 12, bidirectional=True)\n",
      "      (1-5): 5 x LSTM(24, 12, bidirectional=True)\n",
      "    )\n",
      "    (ln_layers): ModuleList(\n",
      "      (0-5): 6 x LayerNorm((24,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (residual_projections): ModuleList(\n",
      "      (0): Linear(in_features=1, out_features=24, bias=True)\n",
      "      (1-5): 5 x None\n",
      "    )\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (lstm_layers): ModuleList(\n",
      "      (0): LSTM(1, 24)\n",
      "      (1-5): 5 x LSTM(24, 24)\n",
      "    )\n",
      "    (ln_layers): ModuleList(\n",
      "      (0-5): 6 x LayerNorm((24,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (residual_projections): ModuleList(\n",
      "      (0): Linear(in_features=1, out_features=24, bias=True)\n",
      "      (1-5): 5 x None\n",
      "    )\n",
      "    (fc_out): Linear(in_features=24, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch [1/50], Train Loss: 2.773680, Validation Loss: 1.360995\n",
      "Epoch [2/50], Train Loss: 1.508795, Validation Loss: 1.349250\n",
      "Epoch [3/50], Train Loss: 1.450119, Validation Loss: 1.324387\n",
      "Epoch [4/50], Train Loss: 1.435745, Validation Loss: 1.336141\n",
      "Epoch [5/50], Train Loss: 1.430073, Validation Loss: 1.337913\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 15\u001b[0m\n\u001b[0;32m     11\u001b[0m paramsCF[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataAugment\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m trainDataAugment\n\u001b[0;32m     13\u001b[0m trainData, testData \u001b[38;5;241m=\u001b[39m PreparingDatasetCF(thumbUnit, paramsCF, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[1;32m---> 15\u001b[0m bestWeightsCF, _, _, modleParametersCF \u001b[38;5;241m=\u001b[39m \u001b[43mtrainModelCF\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m\u001b[49m\u001b[43mparamsCF\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlenSource\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparamsCF\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlenTarget\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainData\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestData\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m trafficModelCF, _ \u001b[38;5;241m=\u001b[39m createModelCF(modleParametersCF)\n\u001b[0;32m     19\u001b[0m trafficModelCF\u001b[38;5;241m.\u001b[39mload_state_dict(bestWeightsCF)\n",
      "File \u001b[1;32mc:\\Users\\Ye\\Documents\\YuYeh_Documents\\L2S\\Projects\\context_aware_traffic_predictor\\libs\\TrafficPredictor\\ContextFree\\TrainingFuncs.py:24\u001b[0m, in \u001b[0;36mtrainModelByDefaultSetting\u001b[1;34m(lenSource, lenTarget, trainData, testData, verbose)\u001b[0m\n\u001b[0;32m     22\u001b[0m parameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_size\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m sources\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m     23\u001b[0m parameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_size\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m---> 24\u001b[0m best_model, avg_train_loss_history, avg_test_loss_history \u001b[38;5;241m=\u001b[39m \u001b[43mtrainModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainData\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestData\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m best_model, avg_train_loss_history, avg_test_loss_history, parameters\n",
      "File \u001b[1;32mc:\\Users\\Ye\\Documents\\YuYeh_Documents\\L2S\\Projects\\context_aware_traffic_predictor\\libs\\TrafficPredictor\\ContextFree\\TrainingFuncs.py:31\u001b[0m, in \u001b[0;36mtrainModel\u001b[1;34m(parameters, trainData, testData, verbose)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrainModel\u001b[39m(parameters, trainData, testData, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     28\u001b[0m     model, criterion, optimizer, train_loader, test_loader, device \u001b[38;5;241m=\u001b[39m prepareTraining(\n\u001b[0;32m     29\u001b[0m         parameters, trainData, testData, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[1;32m---> 31\u001b[0m     best_model, avg_train_loss_history, avg_test_loss_history \u001b[38;5;241m=\u001b[39m \u001b[43mtrainModelHelper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m best_model, avg_train_loss_history, avg_test_loss_history\n",
      "File \u001b[1;32mc:\\Users\\Ye\\Documents\\YuYeh_Documents\\L2S\\Projects\\context_aware_traffic_predictor\\libs\\TrafficPredictor\\ContextFree\\TrainingFuncs.py:65\u001b[0m, in \u001b[0;36mtrainModelHelper\u001b[1;34m(parameters, model, criterion, optimizer, device, train_loader, test_loader, verbose)\u001b[0m\n\u001b[0;32m     62\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     63\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 65\u001b[0m     total_train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m avg_train_loss \u001b[38;5;241m=\u001b[39m total_train_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m#======================Test Loss=====================\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for lenWindow in lenWindow_list:\n",
    "    print(f\"================== lenWindow = {lenWindow} =================\")\n",
    "    trainDataAugment = True\n",
    "    verbose = True\n",
    "\n",
    "    paramsCF = {}\n",
    "    paramsCF['lenWindow'] = lenWindow\n",
    "    paramsCF['lenSource'] = 10\n",
    "    paramsCF['lenTarget'] = 1\n",
    "    paramsCF['trainRatio'] = train_ratio\n",
    "    paramsCF['dataAugment'] = trainDataAugment\n",
    "\n",
    "    trainData, testData = PreparingDatasetCF(thumbUnit, paramsCF, verbose=verbose)\n",
    "\n",
    "    bestWeightsCF, _, _, modleParametersCF = trainModelCF(\n",
    "    paramsCF['lenSource'], paramsCF['lenTarget'], trainData, testData, verbose=verbose)\n",
    "\n",
    "    trafficModelCF, _ = createModelCF(modleParametersCF)\n",
    "    trafficModelCF.load_state_dict(bestWeightsCF)\n",
    "\n",
    "    paramsCF['dataAugment'] = False\n",
    "    trainDataValid, testDataValid = PreparingDatasetCF(thumbUnit, paramsCF, verbose=verbose)\n",
    "    actual_trafficCF_train, predicted_trafficCF_train = evaluateModelCF(trafficModelCF, trainDataValid)\n",
    "    resultsTrain = {}\n",
    "    resultsTrain['trafficTarget_actual'] = actual_trafficCF_train\n",
    "    resultsTrain['trafficTarget_predicted'] = predicted_trafficCF_train\n",
    "    actual_trafficCF_test, predicted_trafficCF_test = evaluateModelCF(trafficModelCF, testDataValid)\n",
    "    resultsTest = {}\n",
    "    resultsTest['trafficTarget_actual'] = actual_trafficCF_test\n",
    "    resultsTest['trafficTarget_predicted'] = predicted_trafficCF_test\n",
    "\n",
    "    plt.plot(resultsTest['trafficTarget_actual'][0:200])\n",
    "    plt.plot(resultsTest['trafficTarget_predicted'][0:200])\n",
    "    plt.show()\n",
    "\n",
    "    #============= Save Results =============\n",
    "    dbpString = encode_float_filename(dbParams)\n",
    "    with open(f\"Results/TrafficPredictor/evaluate/CF/{direction}_{lenWindow}_{mode}_{dbpString}_train.pkl\", \"wb\") as file:\n",
    "        pickle.dump(resultsTrain, file)\n",
    "    with open(f\"Results/TrafficPredictor/evaluate/CF/{direction}_{lenWindow}_{mode}_{dbpString}_test.pkl\", \"wb\") as file:\n",
    "        pickle.dump(resultsTest, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== lenWindow = 10 =================\n",
      "Train size: 83253, Test size: 20814\n",
      "(83233, 10, 3)\n",
      "(83233, 1, 3)\n",
      "Size of train loader: 11, Size of test loader: 3\n",
      "Used device: cuda\n",
      "Size of model: 19661\n",
      "TrafficPredictorContextAssisted(\n",
      "  (dbf2traffic): DeadFeaturesToTrafficLayer(\n",
      "    (input_layer): Sequential(\n",
      "      (0): Linear(in_features=66, out_features=64, bias=True)\n",
      "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Dropout(p=0.8, inplace=False)\n",
      "    )\n",
      "    (hidden_layers): ModuleList(\n",
      "      (0-2): 3 x Sequential(\n",
      "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Dropout(p=0.8, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (trans2transmission_layer): Linear(in_features=64, out_features=10, bias=True)\n",
      "    (sigmoid): Sigmoid()\n",
      "    (trans2traffic_layer): Linear(in_features=74, out_features=1, bias=True)\n",
      "    (trans2trafficClass_layer): Linear(in_features=74, out_features=11, bias=True)\n",
      "  )\n",
      "  (contextAdjuster): ContextAdjuster(\n",
      "    (layers): Sequential(\n",
      "      (Linear_1): Linear(in_features=3, out_features=12, bias=True)\n",
      "      (BatchNorm_1): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (ReLU_1): ReLU()\n",
      "      (Dropout_1): Dropout(p=0.8, inplace=False)\n",
      "      (Linear_2): Linear(in_features=12, out_features=12, bias=True)\n",
      "      (BatchNorm_2): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (ReLU_2): ReLU()\n",
      "      (Dropout_2): Dropout(p=0.8, inplace=False)\n",
      "      (Linear_3): Linear(in_features=12, out_features=12, bias=True)\n",
      "      (BatchNorm_3): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (ReLU_3): ReLU()\n",
      "      (Dropout_3): Dropout(p=0.8, inplace=False)\n",
      "      (Linear_4): Linear(in_features=12, out_features=12, bias=True)\n",
      "      (BatchNorm_4): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (ReLU_4): ReLU()\n",
      "      (Dropout_4): Dropout(p=0.8, inplace=False)\n",
      "      (Linear_5): Linear(in_features=12, out_features=12, bias=True)\n",
      "      (BatchNorm_5): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (ReLU_5): ReLU()\n",
      "      (Dropout_5): Dropout(p=0.8, inplace=False)\n",
      "    )\n",
      "    (output_layer): Linear(in_features=12, out_features=3, bias=True)\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      "  (reluOut): ReLU()\n",
      ")\n",
      "Epoch [1/50], Train Loss: 939.4732, Validation Loss: 481.9525, Validation Loss (Traffic): 5.1299\n",
      "Epoch [2/50], Train Loss: 573.0629, Validation Loss: 481.6013, Validation Loss (Traffic): 3.6239\n",
      "Epoch [3/50], Train Loss: 495.6954, Validation Loss: 476.0035, Validation Loss (Traffic): 2.0493\n",
      "Epoch [4/50], Train Loss: 468.8192, Validation Loss: 447.9656, Validation Loss (Traffic): 3.6522\n",
      "Epoch [5/50], Train Loss: 454.1596, Validation Loss: 436.4237, Validation Loss (Traffic): 3.4858\n",
      "Epoch [6/50], Train Loss: 444.6002, Validation Loss: 429.3210, Validation Loss (Traffic): 3.3262\n",
      "Epoch [7/50], Train Loss: 435.1092, Validation Loss: 421.7719, Validation Loss (Traffic): 4.3303\n",
      "Epoch [8/50], Train Loss: 429.8721, Validation Loss: 431.9115, Validation Loss (Traffic): 2.6417\n",
      "Epoch [9/50], Train Loss: 425.4478, Validation Loss: 414.2255, Validation Loss (Traffic): 2.7969\n",
      "Epoch [10/50], Train Loss: 420.8113, Validation Loss: 399.2520, Validation Loss (Traffic): 1.8529\n",
      "Epoch [11/50], Train Loss: 417.9427, Validation Loss: 395.9935, Validation Loss (Traffic): 1.3600\n",
      "Epoch [12/50], Train Loss: 413.8660, Validation Loss: 400.5182, Validation Loss (Traffic): 1.0558\n",
      "Epoch [13/50], Train Loss: 410.1281, Validation Loss: 394.6161, Validation Loss (Traffic): 1.0202\n",
      "Epoch [14/50], Train Loss: 408.9146, Validation Loss: 390.6180, Validation Loss (Traffic): 1.0129\n",
      "Epoch [15/50], Train Loss: 404.0957, Validation Loss: 393.4153, Validation Loss (Traffic): 1.0966\n",
      "Epoch [16/50], Train Loss: 403.1248, Validation Loss: 392.1392, Validation Loss (Traffic): 1.0147\n",
      "Epoch [17/50], Train Loss: 401.0305, Validation Loss: 394.6128, Validation Loss (Traffic): 0.9970\n",
      "Epoch [18/50], Train Loss: 399.1719, Validation Loss: 389.0365, Validation Loss (Traffic): 0.9799\n",
      "Epoch [19/50], Train Loss: 397.9147, Validation Loss: 380.5330, Validation Loss (Traffic): 0.9756\n",
      "Epoch [20/50], Train Loss: 396.2234, Validation Loss: 383.6444, Validation Loss (Traffic): 0.9862\n",
      "Epoch [21/50], Train Loss: 395.6212, Validation Loss: 384.3394, Validation Loss (Traffic): 0.9968\n",
      "Epoch [22/50], Train Loss: 394.9918, Validation Loss: 397.7279, Validation Loss (Traffic): 1.1655\n",
      "Epoch [23/50], Train Loss: 394.4208, Validation Loss: 383.1080, Validation Loss (Traffic): 0.9878\n",
      "Epoch [24/50], Train Loss: 393.7789, Validation Loss: 380.5270, Validation Loss (Traffic): 0.9742\n",
      "Epoch [25/50], Train Loss: 393.0939, Validation Loss: 381.9010, Validation Loss (Traffic): 0.9860\n",
      "Epoch [26/50], Train Loss: 392.9677, Validation Loss: 384.1335, Validation Loss (Traffic): 1.0068\n",
      "Epoch [27/50], Train Loss: 392.1780, Validation Loss: 379.3441, Validation Loss (Traffic): 0.9606\n",
      "Epoch [28/50], Train Loss: 391.7628, Validation Loss: 379.7616, Validation Loss (Traffic): 0.9776\n",
      "Epoch [29/50], Train Loss: 391.4730, Validation Loss: 388.1509, Validation Loss (Traffic): 1.0883\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(sources\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(lastTranmittedContext\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 19\u001b[0m bestWeightsCA, _, _, modleParametersCA \u001b[38;5;241m=\u001b[39m \u001b[43mtrainModelCA\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m\u001b[49m\u001b[43mparamsCA\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlenSource\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparamsCA\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlenTarget\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainData\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestData\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m#============= Evaluatation =============\u001b[39;00m\n\u001b[0;32m     23\u001b[0m trafficModelCA, _ \u001b[38;5;241m=\u001b[39m createModelCA(modleParametersCA)\n",
      "File \u001b[1;32mc:\\Users\\Ye\\Documents\\YuYeh_Documents\\L2S\\Projects\\context_aware_traffic_predictor\\libs\\TrafficPredictor\\ContextAssisted\\TrainingFuncs.py:37\u001b[0m, in \u001b[0;36mtrainModelByDefaultSetting\u001b[1;34m(len_source, len_target, trainData, testData, verbose)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrainModelByDefaultSetting\u001b[39m(len_source, len_target, trainData, testData, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     35\u001b[0m     parameters \u001b[38;5;241m=\u001b[39m getDefaultModelParams(len_source, len_target, trainData)\n\u001b[1;32m---> 37\u001b[0m     best_model, avg_train_loss_history, avg_test_loss_history \u001b[38;5;241m=\u001b[39m \u001b[43mtrainModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainData\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestData\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m best_model, avg_train_loss_history, avg_test_loss_history, parameters\n",
      "File \u001b[1;32mc:\\Users\\Ye\\Documents\\YuYeh_Documents\\L2S\\Projects\\context_aware_traffic_predictor\\libs\\TrafficPredictor\\ContextAssisted\\TrainingFuncs.py:44\u001b[0m, in \u001b[0;36mtrainModel\u001b[1;34m(parameters, trainData, testData, verbose)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrainModel\u001b[39m(parameters, trainData, testData, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     41\u001b[0m     model, criterion, optimizer, train_loader, test_loader, device \u001b[38;5;241m=\u001b[39m prepareTraining(\n\u001b[0;32m     42\u001b[0m         parameters, trainData, testData, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[1;32m---> 44\u001b[0m     best_model, avg_train_loss_history, avg_test_loss_history \u001b[38;5;241m=\u001b[39m \u001b[43mtrainModelHelper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m best_model, avg_train_loss_history, avg_test_loss_history\n",
      "File \u001b[1;32mc:\\Users\\Ye\\Documents\\YuYeh_Documents\\L2S\\Projects\\context_aware_traffic_predictor\\libs\\TrafficPredictor\\ContextAssisted\\TrainingFuncs.py:76\u001b[0m, in \u001b[0;36mtrainModelHelper\u001b[1;34m(parameters, model, criterion, optimizer, device, train_loader, test_loader, verbose)\u001b[0m\n\u001b[0;32m     73\u001b[0m last_trans_sources \u001b[38;5;241m=\u001b[39m last_trans_sources\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     75\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 76\u001b[0m out_traffic, out_traffic_class, out_trans, out_target \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_trans_sources\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msourcesNoSmooth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m loss, _ \u001b[38;5;241m=\u001b[39m criterion(\n\u001b[0;32m     78\u001b[0m     out_traffic, traffics,\n\u001b[0;32m     79\u001b[0m     out_traffic_class, traffics_class,\n\u001b[0;32m     80\u001b[0m     out_trans, transmissions,\n\u001b[0;32m     81\u001b[0m     out_target, targets\n\u001b[0;32m     82\u001b[0m )\n\u001b[0;32m     83\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\Ye\\miniconda3\\envs\\traffic_predictor_3_9\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Ye\\miniconda3\\envs\\traffic_predictor_3_9\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Ye\\Documents\\YuYeh_Documents\\L2S\\Projects\\context_aware_traffic_predictor\\libs\\TrafficPredictor\\ContextAssisted\\TrafficPredictorEnhanced.py:164\u001b[0m, in \u001b[0;36mTrafficPredictorContextAssisted.forward\u001b[1;34m(self, src, last_trans_src, srcNoSmooth)\u001b[0m\n\u001b[0;32m    162\u001b[0m motion_predict \u001b[38;5;241m=\u001b[39m  torch\u001b[38;5;241m.\u001b[39mclamp(motion_predict, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    163\u001b[0m motion_feature \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([motion_predict, last_trans_src], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 164\u001b[0m db_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mComputeDeadbandFeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmotion_feature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    165\u001b[0m traffic_est, traffic_class_est, transmission_est \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdbf2traffic(db_features)\n\u001b[0;32m    166\u001b[0m traffic_est \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreluOut(traffic_est)\n",
      "File \u001b[1;32mc:\\Users\\Ye\\Documents\\YuYeh_Documents\\L2S\\Projects\\context_aware_traffic_predictor\\libs\\TrafficPredictor\\ContextAssisted\\TrafficPredictorEnhanced.py:144\u001b[0m, in \u001b[0;36mTrafficPredictorContextAssisted.ComputeDeadbandFeatures\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    142\u001b[0m dist_b \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt(dist_sq_b\u001b[38;5;241m.\u001b[39mclamp_min(\u001b[38;5;241m1e-12\u001b[39m))  \u001b[38;5;66;03m# (B,T,T)\u001b[39;00m\n\u001b[0;32m    143\u001b[0m i_idx, j_idx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtril_indices(T, T, offset\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 144\u001b[0m pairwise_features_b \u001b[38;5;241m=\u001b[39m \u001b[43mdist_b\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    145\u001b[0m mag_b \u001b[38;5;241m=\u001b[39m mag\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# (B,T)\u001b[39;00m\n\u001b[0;32m    146\u001b[0m features_b \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([mag_b, pairwise_features_b], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for lenWindow in lenWindow_list:\n",
    "    print(f\"================== lenWindow = {lenWindow} =================\")\n",
    "    trainDataAugment = True\n",
    "    verbose = True\n",
    "\n",
    "    paramsCA = {}\n",
    "    paramsCA['lenSource'] = lenWindow\n",
    "    paramsCA['lenTarget'] = lenWindow\n",
    "    paramsCA['trainRatio'] = train_ratio\n",
    "    paramsCA['dataAugment'] = trainDataAugment\n",
    "    paramsCA['smoothFc'] = 1.5\n",
    "    paramsCA['smoothOrder'] = 3\n",
    "\n",
    "    #============= Training =============\n",
    "    trainData, testData = PreparingDatasetCA(thumbUnit, paramsCA, verbose=verbose)\n",
    "    (sources, _, lastTranmittedContext, _, _, _, _, _) = trainData\n",
    "    print(sources.shape)\n",
    "    print(lastTranmittedContext.shape)\n",
    "    bestWeightsCA, _, _, modleParametersCA = trainModelCA(\n",
    "    paramsCA['lenSource'], paramsCA['lenTarget'], trainData, testData, verbose=verbose)\n",
    "\n",
    "    #============= Evaluatation =============\n",
    "    trafficModelCA, _ = createModelCA(modleParametersCA)\n",
    "    trafficModelCA.load_state_dict(bestWeightsCA)\n",
    "    paramsValid = paramsCA.copy()\n",
    "    paramsValid['dataAugment'] = False\n",
    "    trainData, testData = PreparingDatasetCA(thumbUnit, paramsValid, verbose=verbose)\n",
    "    resultsTrain = evaluateModelCA(trafficModelCA, trainData)\n",
    "    resultsTest = evaluateModelCA(trafficModelCA, testData)\n",
    "\n",
    "    #print(f\"actual_class_shape: {resultsTrain['classDistribu_actual'].shape}, predicted_class_shape: {resultsTrain['classDistribu_predicted'].shape}\")\n",
    "\n",
    "    plt.plot(resultsTest['trafficTarget_actual'][0:200])\n",
    "    plt.plot(resultsTest['trafficTarget_predicted'][0:200])\n",
    "    plt.show()\n",
    "\n",
    "    #============= Save Results =============\n",
    "    dbpString = encode_float_filename(dbParams)\n",
    "    with open(f\"Results/TrafficPredictor/evaluate/CA/{direction}_{lenWindow}_{mode}_{dbpString}_train.pkl\", \"wb\") as file:\n",
    "        pickle.dump(resultsTrain, file)\n",
    "    with open(f\"Results/TrafficPredictor/evaluate/CA/{direction}_{lenWindow}_{mode}_{dbpString}_test.pkl\", \"wb\") as file:\n",
    "        pickle.dump(resultsTest, file)\n",
    "    with open(f\"Results/TrafficPredictor/modelParams/{direction}_{lenWindow}_{mode}_{dbpString}.pkl\", \"wb\") as file:\n",
    "        pickle.dump(modleParametersCA, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traffic_predictor_3_9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
